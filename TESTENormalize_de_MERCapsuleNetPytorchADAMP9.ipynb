{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MendesEric/ICTrab/blob/main/TESTENormalize_de_MERCapsuleNetPytorchADAMP9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yL_6qvDnB7_0"
      },
      "source": [
        "# Net Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOrZIZms6OPy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "def squash(inputs, axis=-1):\n",
        "    \"\"\"\n",
        "    Do squashing\n",
        "    :param inputs (tensor): tensor of dim [M, num_capsules, capsule_dim]\n",
        "    :param axis: the dim to apply squash\n",
        "    :return:\n",
        "        (tensor): squashed tensor of dim [M, num_capsules, capsule_dim]\n",
        "    \"\"\"\n",
        "    norm = torch.norm(inputs, p=2, dim=axis, keepdim=True)\n",
        "    scale = norm ** 2 / (1 + norm ** 2) / (norm + 1e-8)\n",
        "    return scale * inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FgN7r19OxOMD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import torch\n",
        "from torch.optim import Adam, SGD, lr_scheduler\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import recall_score, f1_score\n",
        "from sklearn.utils import shuffle\n",
        "import pickle\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import CrossEntropyLoss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYz-uh9axTp_"
      },
      "outputs": [],
      "source": [
        "class PrimaryCapsule(nn.Module):\n",
        "    \"\"\"\n",
        "    Apply Conv2D with `out_channels` and then reshape to get capsules\n",
        "    :param in_channels: input channels\n",
        "    :param out_channels: output channels\n",
        "    :param dim_caps: dimension of capsule\n",
        "    :param kernel_size: kernel size\n",
        "    :return: output tensor, size=[batch, num_caps, dim_caps]\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, dim_caps, kernel_size, stride=1, padding=0):\n",
        "        super(PrimaryCapsule, self).__init__()\n",
        "        self.dim_caps = dim_caps\n",
        "        self.conv2d = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "\n",
        "    def forward(self, x):\n",
        "        outputs = self.conv2d(x)\n",
        "        outputs = outputs.permute(0, 2, 3, 1).contiguous() # I add\n",
        "        outputs = outputs.view(x.size(0), -1, self.dim_caps)\n",
        "        return squash(outputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZ1cPV7ixXk3"
      },
      "outputs": [],
      "source": [
        "class MECapsule(nn.Module):\n",
        "    \"\"\"\n",
        "    The ME capsule layer. Dense layer has `in_num` inputs, each is a scalar, the\n",
        "    output of the neuron from the former layer, and it has `out_num` output neurons.\n",
        "    MECapsule just expands the output of the neuron from scalar to vector.\n",
        "    :param in_num_caps: number of cpasules inputted to this layer\n",
        "    :param in_dim_caps: dimension of input capsules\n",
        "    :param out_num_caps: number of capsules outputted from this layer\n",
        "    :param out_dim_caps: dimension of output capsules\n",
        "    :param routings: number of iterations for the routing algorithm\n",
        "    \"\"\"\n",
        "    def __init__(self, in_num_caps, in_dim_caps, out_num_caps, out_dim_caps, routings=3):\n",
        "        super(MECapsule, self).__init__()\n",
        "        self.in_num_caps = in_num_caps\n",
        "        self.in_dim_caps = in_dim_caps\n",
        "        self.out_num_caps = out_num_caps\n",
        "        self.out_dim_caps = out_dim_caps\n",
        "        self.routings = routings\n",
        "        self.weight = nn.Parameter(0.01 * torch.randn(out_num_caps, in_num_caps, out_dim_caps, in_dim_caps))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_hat = torch.squeeze(torch.matmul(self.weight, x[:, None, :, :, None]), dim=-1)\n",
        "        x_hat_detached = x_hat.detach()\n",
        "\n",
        "        b = torch.zeros(x.size(0), self.out_num_caps, self.in_num_caps).cuda()\n",
        "\n",
        "        for i in range(self.routings):\n",
        "            c = F.softmax(b, dim=1)\n",
        "\n",
        "            if i == self.routings - 1:\n",
        "                outputs = squash(torch.sum(c[:, :, :, None] * x_hat, dim=-2, keepdim=True))\n",
        "            else:\n",
        "                outputs = squash(torch.sum(c[:, :, :, None] * x_hat_detached, dim=-2, keepdim=True))\n",
        "                b = b + torch.sum(outputs * x_hat_detached, dim=-1)\n",
        "\n",
        "        return torch.squeeze(outputs, dim=-2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRcglRUlC1D7"
      },
      "source": [
        "# Resnet SETUP\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGnBFjSyxdbM"
      },
      "outputs": [],
      "source": [
        "from torchvision import models\n",
        "from torchvision.models import ResNet18_Weights, ResNet101_Weights, ResNet50_Weights, ResNet34_Weights\n",
        "class ResNetLayers(nn.Module):\n",
        "\tdef __init__(self, is_freeze=True):\n",
        "\t\tsuper(ResNetLayers, self).__init__()\n",
        "\t\tself.model = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
        "\t\tdelattr(self.model, 'layer4')\n",
        "\t\tdelattr(self.model, 'avgpool')\n",
        "\t\tdelattr(self.model, 'fc')\n",
        "\n",
        "\t\tif is_freeze:\n",
        "\t\t\tfor index, p in enumerate(self.model.parameters()):\n",
        "\t\t\t\tif index == 15:\n",
        "\t\t\t\t\tbreak\n",
        "\t\t\t\tp.requires_grad = False\n",
        "\n",
        "\tdef forward(self, x):\n",
        "\t\toutput = self.model.conv1(x)\n",
        "\t\toutput = self.model.bn1(output)\n",
        "\t\toutput = self.model.relu(output)\n",
        "\t\toutput = self.model.layer1(output)\n",
        "\t\toutput = self.model.layer2(output)\n",
        "\t\toutput = self.model.layer3(output)\n",
        "\t\treturn output\n",
        "\n",
        "\n",
        "class VGGLayers(nn.Module):\n",
        "\tdef __init__(self, is_freeze=True):\n",
        "\t\tsuper(VGGLayers, self).__init__()\n",
        "\t\tself.model = models.vgg11(weights=True).features[:11]\n",
        "\n",
        "\t\tif is_freeze:\n",
        "\t\t\tfor i in range(4):\n",
        "\t\t\t\tfor p in self.model[i].parameters():\n",
        "\t\t\t\t\tp.requires_grad = False\n",
        "\n",
        "\tdef forward(self, x):\n",
        "\t\t# x = [B, 3, 224, 224]\n",
        "\t\treturn self.model(x)  # [B, 256, 20, 20]\n",
        "\n",
        "\n",
        "backbone = {'vgg': VGGLayers, 'resnet': ResNetLayers}\n",
        "\n",
        "\n",
        "class MECapsuleNet(nn.Module):\n",
        "\t\"\"\"\n",
        "\tA Capsule Network on Micro-expression.\n",
        "\t:param input_size: data size = [channels, width, height]\n",
        "\t:param classes: number of classes\n",
        "\t:param routings: number of routing iterations\n",
        "\tShape:\n",
        "\t\t- Input: (batch, channels, width, height), optional (batch, classes) .\n",
        "\t\t- Output:((batch, classes), (batch, channels, width, height))\n",
        "\t\"\"\"\n",
        "\n",
        "\tdef __init__(self, input_size, classes, routings, conv_name='resnet', is_freeze=True):\n",
        "\t\tsuper(MECapsuleNet, self).__init__()\n",
        "\t\tself.input_size = input_size\n",
        "\t\tself.classes = classes\n",
        "\t\tself.routings = routings\n",
        "\n",
        "\t\tself.conv = backbone[conv_name](is_freeze)\n",
        "\t\t# self.channel_reducer = nn.Conv2d(1024, 256, kernel_size=1)  # 1x1 convolution\n",
        "\t\tself.conv1 = nn.Conv2d(1024, 256, kernel_size=9, stride=1, padding=0)\n",
        "\n",
        "\t\tself.primarycaps = PrimaryCapsule(256, 32 * 8, 8, kernel_size=9, stride=2, padding=0)\n",
        "\n",
        "\t\tself.digitcaps = MECapsule(in_num_caps=32 * 6 * 6,\n",
        "\t\t                           in_dim_caps=8,\n",
        "\t\t                           out_num_caps=self.classes,\n",
        "\t\t                           out_dim_caps=16,\n",
        "\t\t                           routings=routings)\n",
        "\n",
        "\t\tself.relu = nn.ReLU()\n",
        "\n",
        "\tdef forward(self, x, y=None):\n",
        "\t\tx = self.conv(x)\n",
        "\t\t# x = self.channel_reducer(x)  # Reduce channels before passing to conv1\n",
        "\t\tx = self.relu(self.conv1(x))\n",
        "\t\tx = self.primarycaps(x)\n",
        "\t\tx = self.digitcaps(x)\n",
        "\t\tlength = x.norm(dim=-1)\n",
        "\t\treturn length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vr1bPc1wxlVv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import recall_score, f1_score\n",
        "\n",
        "class Meter(object):\n",
        "\n",
        "\tdef __init__(self):\n",
        "\t\t\"\"\"\n",
        "\t\tTo record the measure the performance.\n",
        "\t\t\"\"\"\n",
        "\t\tself.Y_true = np.array([], dtype=np.int64)\n",
        "\t\tself.Y_pred = np.array([], dtype=np.int64)\n",
        "\n",
        "\n",
        "\tdef add(self, y_true, y_pred, verbose=False):\n",
        "\t\tif len(self.Y_true.shape) != len(y_true.shape):\n",
        "\t\t\tprint('shape self.Y_true', self.Y_true.shape)\n",
        "\t\t\tprint('y_true', y_true.shape)\n",
        "\n",
        "\t\tself.Y_true = np.concatenate((self.Y_true, y_true))\n",
        "\t\tself.Y_pred = np.concatenate((self.Y_pred, y_pred))\n",
        "\n",
        "\tdef reset(self):\n",
        "\t\tself.Y_true = np.array([], dtype=np.int64)\n",
        "\t\tself.Y_pred = np.array([], dtype=np.int64)\n",
        "\n",
        "\tdef value(self):\n",
        "\t\teye = np.eye(3, dtype=np.int64)\n",
        "\t\tY_true = eye[self.Y_true]\n",
        "\t\tY_pred = eye[self.Y_pred]\n",
        "\t\tuar = recall_score(Y_true, Y_pred, average=None, zero_division=1)\n",
        "\t\tuf1 = f1_score(Y_true, Y_pred, average=None, zero_division=1)\n",
        "\t\treturn uar, uf1\n",
        "\n",
        "\n",
        "class UF1(nn.Module):\n",
        "\n",
        "\tdef __init__(self):\n",
        "\t\tsuper(UF1, self).__init__()\n",
        "\n",
        "\n",
        "\tdef forward(self, outputs, targets):\n",
        "\t\t\"\"\"Compute Unweighted F1 score on k folds of LOSO\n",
        "\t\tArgs:\n",
        "\t\t\toutputs (list): [k folds]\n",
        "\t\t\ttargets (list): [k folds]\n",
        "\t\tReturns:\n",
        "\t\t\tUF1 = F1c/C\n",
        "\t\t\"\"\"\n",
        "\n",
        "\t\tk_folds = len(outputs)\n",
        "\t\tnum_classes = outputs[0].size(1)\n",
        "\t\tUF1 = 0.0\n",
        "\t\tfor c in range(num_classes):\n",
        "\t\t\tTPc, FPc, FNc = 0.0, 0.0, 0.0\n",
        "\n",
        "\t\t\tfor fold in range(k_folds):\n",
        "\t\t\t\tres = self.compute_on_fold(outputs[fold][:, c], targets[fold][:, c])\n",
        "\t\t\t\tTPc += res[0]\n",
        "\t\t\t\tFPc += res[1]\n",
        "\t\t\t\tFNc += res[2]\n",
        "\n",
        "\t\t\tF1c = (2*TPc) / (2 * TPc + FPc + FNc)\n",
        "\n",
        "\t\tUF1 += F1c / num_classes\n",
        "\t\treturn UF1\n",
        "\n",
        "\t@staticmethod\n",
        "\tdef compute_on_fold(output, target):\n",
        "\t\t\"\"\"\n",
        "\t\tArgs\n",
        "\t\t\toutput (torch.tensor): [1, 0, 1, 1, 1]\n",
        "\t\t\ttarget (torch.tensor): [1, 1, 1, 1, 0]\n",
        "\t\tReturns:\n",
        "\t\t\t(TP, FP, FN): True Positive, False Positive, False Negative\n",
        "\t\t\tTP = 3, FP = 1, FN = 1\n",
        "\t\t\"\"\"\n",
        "\t\toutput = output >= 0.5\n",
        "\t\ttarget = target >= 0.5\n",
        "\n",
        "\t\tTP = target.__and__(output).sum()\n",
        "\t\tFP = (1 - target).__and__(output).sum()\n",
        "\t\tFN = target.__and__(1 - output).sum()\n",
        "\t\treturn TP.float(), FP.float(), FN.float()\n",
        "\n",
        "\n",
        "class UARecall(nn.Module):\n",
        "\n",
        "\tdef __init__(self):\n",
        "\t\tsuper(UARecall, self).__init__()\n",
        "\n",
        "\tdef forward(self, outputs, targets):\n",
        "\t\t\"\"\"Compute Unweighted Average Recall\n",
        "\t\tArgs:\n",
        "\t\t\toutputs:\n",
        "\t\t\ttargets:\n",
        "\t\tReturns:\n",
        "\t\t\tUAR = 1/C * sum (Acc_c) where Acc_c is per-class accuracy: Acc_c = TPc/n_c\n",
        "\t\t\"\"\"\n",
        "\t\tnum_classes = outputs.size(1)\n",
        "\t\tUAR = 0.0\n",
        "\n",
        "\t\tfor c in range(num_classes):\n",
        "\t\t\tAcc_c = self.compute_acc(outputs[:, c], targets[:, c])\n",
        "\t\t\tUAR += Acc_c / float(num_classes)\n",
        "\t\treturn UAR\n",
        "\n",
        "\t@staticmethod\n",
        "\tdef compute_acc(output, target):\n",
        "\t\toutput = output >= 0.5\n",
        "\t\ttarget = target >= 0.5\n",
        "\n",
        "\t\tTP = target.__and__(output).sum()\n",
        "\t\tNc = len(target)\n",
        "\t\tif Nc == 0:\n",
        "\t\t\tprint('Nc = 0! and TP = ', TP)\n",
        "\t\telse:\n",
        "\t\t\tprint(\"NC is not Zero\", Nc, 'while TP=', TP)\n",
        "\t\tacc = TP.float() / Nc\n",
        "\t\treturn acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vgmqNd-AxwSk"
      },
      "outputs": [],
      "source": [
        "def me_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    The loss function\n",
        "    :param y_true: (tensor) of shape [N, num_classes]\n",
        "    :param y_pred: (tensor) of shape [N, num_classes]\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    L = y_true * torch.clamp(0.99 - y_pred, min=0.) ** 2 + \\\n",
        "        0.5 * (1 - y_true) * torch.clamp(y_pred - 0.01, min=0.) ** 2\n",
        "\n",
        "    # class_weights = torch.tensor([1.0, 10.97, 8.43]).cuda()\n",
        "    # L = L * class_weights\n",
        "\n",
        "    L_margin = L.sum(dim=1).mean()\n",
        "    # print('loss:', L.sum(dim=0))\n",
        "    return L_margin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFf2ptV6x2ae"
      },
      "outputs": [],
      "source": [
        "def one_hot_encode(labels, num_classes=None):\n",
        "\tif num_classes is None:\n",
        "\t\tnum_classes = len(labels.unique())\n",
        "\n",
        "\treturn torch.eye(num_classes, dtype=torch.long).index_select(dim=0, index=labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oroY7F-3yGs_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as transforms\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "class Dataset(data.Dataset):\n",
        "\n",
        "\tdef __init__(self, root, img_paths, img_labels, transform=None, get_aux=False, aux=None):\n",
        "\t\t\"\"\"Load image paths and labels from gt_file\"\"\"\n",
        "\t\tself.root = root\n",
        "\t\tself.transform = transform\n",
        "\t\tself.get_aux = get_aux\n",
        "\t\tself.img_paths = img_paths\n",
        "\t\tself.img_labels = img_labels\n",
        "\t\tself.aux = aux\n",
        "\n",
        "\tdef __getitem__(self, idx):\n",
        "\t\t\"\"\"Load image.\n",
        "\t\tArgs:\n",
        "\t\t\tidx (int): image idx.\n",
        "\t\tReturns:\n",
        "\t\t\timg (tensor): image tensor\n",
        "\t\t\"\"\"\n",
        "\t\timg_path = self.img_paths[idx]\n",
        "\t\timg = Image.open(os.path.join(self.root, img_path)).convert('RGB')\n",
        "\t\tlabel = self.img_labels[idx]\n",
        "\n",
        "\t\tif self.transform:\n",
        "\t\t\timg = self.transform(img)\n",
        "\n",
        "\t\tif not self.get_aux:\n",
        "\t\t\treturn img, label\n",
        "\t\telse:\n",
        "\t\t\treturn img, label, self.aux[idx]\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\treturn len(self.img_paths)\n",
        "\n",
        "\n",
        "def get_triple_meta_data(file_path):\n",
        "\tdf = pd.read_csv(file_path)\n",
        "\ton_paths = list(df.on_frame_path)\n",
        "\tapex_paths = list(df.apex_frame_path)\n",
        "\toff_paths = list(df.off_frame_path)\n",
        "\n",
        "\tpaths = [(on, apex, off) for (on, apex, off) in zip(on_paths, apex_paths, off_paths)]\n",
        "\tlabels = list(df.label)\n",
        "\treturn paths, labels\n",
        "\n",
        "\n",
        "def get_meta_data(df):\n",
        "\tpaths = list(df.apex_frame_path)\n",
        "\tlabels = list(df.label)\n",
        "\n",
        "\treturn paths, labels\n",
        "\n",
        "\n",
        "def data_split(file_path, subject_out_idx=0):\n",
        "\t\"\"\"Split dataset into train set and validation set\n",
        "\t\"\"\"\n",
        "\t# data, subject, clipID, label, apex_frame, apex_frame_path\n",
        "\tdata_sub_column = 'subject'\n",
        "\n",
        "\tdf = pd.read_csv(file_path)\n",
        "\tsubject_list = list(df[data_sub_column].unique())\n",
        "\n",
        "\tsubject_out = subject_list[subject_out_idx]\n",
        "\tprint('subject_out', subject_out)\n",
        "\tdf_train = df[df[data_sub_column] != subject_out]\n",
        "\tdf_val = df[df[data_sub_column] == subject_out]\n",
        "\n",
        "\treturn df_train, df_val\n",
        "\n",
        "\n",
        "def upsample_subdata(df, df_four, number=4):\n",
        "    result = df.copy()\n",
        "    for i in range(df.shape[0]):\n",
        "        quotient = number // 1\n",
        "        remainder = number % 1\n",
        "        remainder = 1 if np.random.rand() < remainder else 0\n",
        "        value = quotient + remainder\n",
        "\n",
        "        tmp = df_four[df_four['subject'] == df.iloc[i]['subject']]\n",
        "        tmp = tmp[tmp['clip'] == df.iloc[i]['clip']]\n",
        "        value = min(value, tmp.shape[0])\n",
        "        tmp = tmp.sample(int(value))\n",
        "        result = pd.concat([result, tmp])\n",
        "    return result\n",
        "\n",
        "\n",
        "def sample_data(df, df_four):\n",
        "\n",
        "\n",
        "  df_neg = df[df.label == 0]\n",
        "  df_pos = df[df.label == 1]\n",
        "  df_sur = df[df.label == 2]\n",
        "\n",
        "  num_sur = 4\n",
        "  num_pos = 5 * df_sur.shape[0] / df_pos.shape[0] - 1\n",
        "  num_neg = 5 * df_sur.shape[0] / df_neg.shape[0] - 1\n",
        "\n",
        "  df_neg = upsample_subdata(df_neg, df_four, num_neg)\n",
        "  df_pos = upsample_subdata(df_pos, df_four, num_pos)\n",
        "  df_sur = upsample_subdata(df_sur, df_four, num_sur)\n",
        "  print('df_neg', df_neg.shape)\n",
        "  print('df_pos', df_pos.shape)\n",
        "  print('df_sur', df_sur.shape)\n",
        "\n",
        "  df = pd.concat([df_neg, df_pos, df_sur])\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pl76OTq1yQu1",
        "outputId": "b3c4f7fc-3543-4b9c-a740-342129f1c64f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ag4VxOOqCGNT"
      },
      "source": [
        "# Transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOoOmxGRyJef"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from sklearn.utils import shuffle\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import AutoAugmentPolicy\n",
        "\n",
        "\n",
        "# data_apex_frame_path = '/content/gdrive/MyDrive/TCC/TCC DATABASES/casme_apexFINAL.csv'\n",
        "# data_four_frames_path = '/content/gdrive/MyDrive/TCC/TCC DATABASES/TesteFinal.csv'\n",
        "# data_apex_frame_path = '/content/gdrive/MyDrive/TCC/TCC DATABASES/data_four_framesC.csv'\n",
        "data_four_frames_path = '/content/gdrive/MyDrive/TCC/TCC DATABASES/data_four_framesC.csv'\n",
        "data_apex_frame_path = '/content/gdrive/MyDrive/TCC/TCC DATABASES/data_four_framesC_editado.csv'\n",
        "data_root = '/content/gdrive/MyDrive/'\n",
        "num_classes = 3\n",
        "batch_size = 32\n",
        "lr = 0.0001\n",
        "lr_decay_value = 0.9\n",
        "epochs = 30\n",
        "x_meter = Meter()\n",
        "batches_scores = []\n",
        "\n",
        "\n",
        "def load_me_data(data_root, file_path, subject_out_idx, batch_size=32, num_workers=2):\n",
        "\tdf_train, df_val = data_split(file_path, subject_out_idx)\n",
        "\tdf_four = pd.read_csv(data_four_frames_path)\n",
        "\tdf_train_sampled = sample_data(df_train, df_four)\n",
        "\tdf_train_sampled = shuffle(df_train_sampled)\n",
        "\n",
        "\ttrain_paths, train_labels = get_meta_data(df_train_sampled)\n",
        "\n",
        "\n",
        "\t# #Trivial Augment\n",
        "\t# train_transforms = transforms.Compose([transforms.Resize((234, 240)),\n",
        "\t#                                        transforms.CenterCrop((224, 224)),\n",
        "\t# \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t transforms.TrivialAugmentWide(),\n",
        "\t# \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t transforms.ToTensor(),\n",
        "\t# \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t transforms.Normalize( mean = (0.485, 0.456, 0.406) , std= (0.229, 0.224, 0.225))])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\t# train_transforms = transforms.Compose([transforms.Resize((234, 240)),\n",
        "\t#                                        transforms.RandomCrop((224, 224)),\n",
        "\t# \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t transforms.RandomRotation(degrees=(-8, 8)),\n",
        "\t# \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t transforms.RandAugment(2,7),\n",
        "\t#                                        transforms.ToTensor(),\n",
        "\t# \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t transforms.Normalize( mean = (0.485, 0.456, 0.406) , std= (0.229, 0.224, 0.225))])\n",
        "\n",
        "\n",
        "  # No AU\n",
        "\n",
        "\t# train_transforms = transforms.Compose([transforms.Resize((234, 240)),\n",
        "\t#                                        transforms.CenterCrop((224, 224)),\n",
        "\t#                                        transforms.ToTensor(),\n",
        "\t# \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t transforms.Normalize( mean = (0.485, 0.456, 0.406) , std= (0.229, 0.224, 0.225))])\n",
        "\n",
        "\n",
        "\n",
        "  # Light AU - 3 parameters\n",
        "\t# train_transforms = transforms.Compose([transforms.Resize((234, 240)),\n",
        "\t#                                        transforms.RandomRotation(degrees=(-8, 8)),\n",
        "\t#                                        transforms.RandomHorizontalFlip(),\n",
        "\t#                                        transforms.ColorJitter(brightness=0.2, contrast=0.2,\n",
        "\t#                                                               saturation=0.2, hue=0.2),\n",
        "\t#                                        transforms.RandomCrop((224, 224)),\n",
        "\t#                                        transforms.ToTensor(),\n",
        "\t# \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t transforms.Normalize( mean = (0.485, 0.456, 0.406) , std= (0.229, 0.224, 0.225))])\n",
        "\n",
        "\t#High AU\n",
        "\ttrain_transforms = transforms.Compose([transforms.Resize((234, 240)),\n",
        "\t                                       transforms.RandomRotation(degrees=(-8, 8)),\n",
        "\t                                       transforms.RandomHorizontalFlip(),\n",
        "\t                                       transforms.ColorJitter(brightness=0.2, contrast=0.2,\n",
        "\t                                                              saturation=0.2, hue=0.2),\n",
        "\t                                       transforms.RandomCrop((224, 224)),\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t transforms.RandomGrayscale(p=0.2),\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t transforms.RandomEqualize(p = 0.1),\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t transforms.RandomAutocontrast(p = 0.1),\n",
        "\t                                       transforms.ToTensor(),\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t transforms.Normalize( mean = (0.485, 0.456, 0.406) , std= (0.229, 0.224, 0.225))])\n",
        "\n",
        "\n",
        "\n",
        "\ttrain_dataset = Dataset(root=data_root,\n",
        "\t                        img_paths=train_paths,\n",
        "\t                        img_labels=train_labels,\n",
        "\t                        transform=train_transforms)\n",
        "\n",
        "\tval_transforms = transforms.Compose([transforms.Resize((234, 240)),\n",
        "\t                                     transforms.CenterCrop((224, 224)),\n",
        "\t                                     transforms.ToTensor(),\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t transforms.Normalize( mean = (0.485, 0.456, 0.406) , std= (0.229, 0.224, 0.225))])\n",
        "\n",
        "\n",
        "\tval_paths, val_labels = get_meta_data(df_val)\n",
        "\n",
        "\tval_dataset = Dataset(root=data_root,\n",
        "\t                      img_paths=val_paths,\n",
        "\t                      img_labels=val_labels,\n",
        "\t                      transform=val_transforms)\n",
        "\n",
        "\ttrain_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "\t                                           batch_size=batch_size,\n",
        "\t                                           num_workers=num_workers,\n",
        "\t                                           shuffle=True)\n",
        "\n",
        "\tval_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
        "\t                                         batch_size=batch_size,\n",
        "\t                                         num_workers=num_workers,\n",
        "\t                                         shuffle=False)\n",
        "\treturn train_loader, val_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRyHSC1ICNTc"
      },
      "source": [
        "# Train test SETUP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHSHvB8y0EYI"
      },
      "outputs": [],
      "source": [
        "def on_epoch(model, optimizer, lr_decay, train_loader, test_loader, epoch):\n",
        "\tmodel.train()\n",
        "\n",
        "\ttrain_loss = 0.0\n",
        "\tcorrect = 0.\n",
        "\tmeter = Meter()\n",
        "\n",
        "\tsteps = len(train_loader.dataset) // batch_size + 1\n",
        "\twith tqdm(total=steps) as progress_bar:\n",
        "\t\tfor i, (x, y) in enumerate(train_loader):  # batch training\n",
        "\t\t\ty = torch.zeros(y.size(0), num_classes).scatter_(1, y.view(-1, 1),\n",
        "\t\t\t                                                 1.)  # change to one-hot coding\n",
        "\t\t\tx, y = x.cuda(), y.cuda()  # convert input data to GPU Variable\n",
        "\n",
        "\t\t\toptimizer.zero_grad()  # set gradients of optimizer to zero\n",
        "\t\t\ty_pred = model(x, y)  # forward\n",
        "\t\t\tloss = me_loss(y, y_pred)  # compute loss\n",
        "\t\t\tloss.backward()  # backward, compute all gradients of loss w.r.t all Variables\n",
        "\t\t\ttrain_loss += loss.item() * x.size(0)  # record the batch loss\n",
        "\t\t\toptimizer.step()  # update the trainable parameters with computed gradients\n",
        "\n",
        "\n",
        "\t\t\ty_pred = y_pred.data.max(1)[1]\n",
        "\t\t\ty_true = y.data.max(1)[1]\n",
        "\n",
        "\t\t\tmeter.add(y_true.cpu().numpy(), y_pred.cpu().numpy())\n",
        "\t\t\tcorrect += y_pred.eq(y_true).cpu().sum()\n",
        "\n",
        "\t\t\tprogress_bar.set_postfix(loss=loss.item(), correct=correct)\n",
        "\t\t\tprogress_bar.update(1)\n",
        "\n",
        "\t\tlr_decay.step()  # decrease the learning rate by multiplying a factor `gamma`\n",
        "\t\ttrain_loss /= float(len(train_loader.dataset))\n",
        "\t\ttrain_acc = float(correct.item()) / float(len(train_loader.dataset))\n",
        "\t\tscores = meter.value()\n",
        "\t\tmeter.reset()\n",
        "\t\tprint('Training UAR: %.4f' % (scores[0].mean()), scores[0])\n",
        "\t\tprint('Training UF1: %.4f' % (scores[1].mean()), scores[1])\n",
        "\n",
        "\tcorrect = 0.\n",
        "\ttest_loss = 0.\n",
        "\n",
        "\tmodel.eval()\n",
        "\tfor i, (x, y) in enumerate(test_loader):  # batch training\n",
        "\t\ty = torch.zeros(y.size(0), num_classes).scatter_(1, y.view(-1, 1),\n",
        "\t\t                                                 1.)  # change to one-hot coding\n",
        "\t\tx, y = x.cuda(), y.cuda()  # convert input data to GPU Variable\n",
        "\n",
        "\t\ty_pred = model(x, y)  # forward\n",
        "\t\tloss = me_loss(y, y_pred)  # compute loss\n",
        "\t\ttest_loss += loss.item() * x.size(0)  # record the batch loss\n",
        "\n",
        "\t\ty_pred = y_pred.data.max(1)[1]\n",
        "\t\ty_true = y.data.max(1)[1]\n",
        "\n",
        "\t\tmeter.add(y_true.cpu().numpy(), y_pred.cpu().numpy())\n",
        "\t\tcorrect += y_pred.eq(y_true).cpu().sum()\n",
        "\n",
        "\t\tif (epoch + 1) % 10 == 0 and i % steps == 0:\n",
        "\t\t\tprint('y_true\\n', y_true[:30])\n",
        "\t\t\tprint('y_pred\\n', y_pred[:30])\n",
        "\n",
        "\tprint('y_true', y.sum(dim=0))\n",
        "\tscores = meter.value()\n",
        "\tprint('Testing UAR: %.4f' % (scores[0].mean()), scores[0])\n",
        "\tprint('Testing UF1: %.4f' % (scores[1].mean()), scores[1])\n",
        "\n",
        "\ttest_loss /= float(len(test_loader.dataset))\n",
        "\ttest_acc = float(correct.item()) / float(len(test_loader.dataset))\n",
        "\treturn train_loss, train_acc, test_loss, test_acc, meter\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mR7KP3ouRpD",
        "outputId": "329cd272-3284-433e-d0f5-324f5aecd95e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting adamp\n",
            "  Downloading adamp-0.3.0.tar.gz (5.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: adamp\n",
            "  Building wheel for adamp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for adamp: filename=adamp-0.3.0-py3-none-any.whl size=5984 sha256=4ef1b3b37eabf2db68ab6e8f7e88041c1087be9b7b11691c404a9919db84261d\n",
            "  Stored in directory: /root/.cache/pip/wheels/33/f9/d6/b2ed816e1f321f6dcf72a99c954223b1259477095f40434979\n",
            "Successfully built adamp\n",
            "Installing collected packages: adamp\n",
            "Successfully installed adamp-0.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip3 install adamp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TGEm_Imuaxi"
      },
      "outputs": [],
      "source": [
        "from adamp import AdamP\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T63jtI1C0c8C"
      },
      "outputs": [],
      "source": [
        "def train_eval(subject_out_idx):\n",
        "\tbest_val_uf1 = 0.0\n",
        "\tbest_val_uar = 0.0\n",
        "\n",
        "\t# Model & others\n",
        "\tmodel = MECapsuleNet(input_size=(3, 224, 224), classes=num_classes, routings=3, is_freeze=True)\n",
        "\tmodel.cuda()\n",
        "\toptimizer = AdamP(model.parameters(), lr=lr)\n",
        "\tlr_decay = lr_scheduler.ExponentialLR(optimizer, gamma=lr_decay_value)\n",
        "\n",
        "\tfor epoch in range(epochs):\n",
        "\t\ttrain_loader, test_loader = load_me_data(data_root, data_apex_frame_path,\n",
        "\t\t                                         subject_out_idx=subject_out_idx,\n",
        "\t\t                                         batch_size=batch_size)\n",
        "\t\ttrain_loss, train_acc, test_loss, test_acc, meter = on_epoch(model, optimizer, lr_decay,\n",
        "\t\t                                                              train_loader, test_loader,\n",
        "\t\t                                                              epoch)\n",
        "\n",
        "\t\tprint(\"==> Subject out: %02d - Epoch %02d: loss=%.5f, train_acc=%.5f, val_loss=%.5f, \"\n",
        "\t\t      \"val_acc=%.4f\"\n",
        "\t\t      % (subject_out_idx+1, epoch, train_loss, train_acc,\n",
        "\t\t         test_loss, test_acc))\n",
        "\n",
        "\t\tscores = meter.value()\n",
        "\t\tif scores[1].mean() >= best_val_uf1:\n",
        "\t\t\tbest_val_uar = scores[0].mean()\n",
        "\t\t\tbest_val_uf1 = scores[1].mean()\n",
        "\t\t\tY_true = meter.Y_true.copy()\n",
        "\t\t\tY_pred = meter.Y_pred.copy()\n",
        "\n",
        "\tx_meter.add(Y_true, Y_pred, verbose=True)\n",
        "\n",
        "\treturn best_val_uar, best_val_uf1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_R3MFKQ9CWfQ"
      },
      "source": [
        "# Training and Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eocnbhIo07ZW"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import time\n",
        "inicio = time.time()\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "name_instance = 'scores_ADAMP_AURandom27Normalize_Resnet50_1.pkl'\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    uar_list = []  # Lista para armazenar os UARs de cada sujeito\n",
        "    uf1_list = []  # Lista para armazenar os UF1s de cada sujeito\n",
        "    subject_indices = list(range(25))  # Lista para os indices dos subjects\n",
        "    random.shuffle(subject_indices)  # randomizando a lista para treinamento aleatorio\n",
        "    for i in subject_indices:\n",
        "        scores = train_eval(subject_out_idx=i)\n",
        "        batches_scores.append(scores)\n",
        "        x_scores = x_meter.value()\n",
        "        current_uar = x_scores[0].mean()  # Calcula a média do UAR\n",
        "        current_uf1 = x_scores[1].mean()  # Calcula a média do UF1\n",
        "        uar_list.append(current_uar)  # Armazena o valor\n",
        "        uf1_list.append(current_uf1)  # Armazena o valor\n",
        "\n",
        "        print('final uar', x_scores[0], current_uar)\n",
        "        print('final uf1', x_scores[1], current_uf1)\n",
        "        print('---- NEXT ---- \\n\\n')\n",
        "    with open(name_instance, 'wb') as file:\n",
        "      data = dict(meter=x_meter, batches_scores=batches_scores, Y_pred = x_meter.Y_pred, Y_true = x_meter.Y_true)\n",
        "      pickle.dump(data, file)\n",
        "\n",
        "fim = time.time()\n",
        "duracao = fim - inicio\n",
        "print(f\"Tempo de execução: {duracao:.4f} segundos\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Criação do gráfico UAR x Subject\n",
        "subjects = range(1, 26)  # Sujeitos de 1 a 25\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(subjects, uar_list, marker='o', linestyle='-', linewidth=2, markersize=8)\n",
        "plt.xlabel('Número da Iteração LOSO', fontsize=12)\n",
        "plt.ylabel('UAR', fontsize=12)\n",
        "plt.title('UAR por Iteração LOSO ', fontsize=14)\n",
        "plt.xticks(subjects)  # Garante todos os sujeitos no eixo\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.savefig('UAR_por_IT.png')  # Salva a figura\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PE_F5kx9ed2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Criação do gráfico UF1 x Subject\n",
        "subjects = range(1, 26)  # Sujeitos de 1 a 25\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(subjects, uf1_list, marker='o', linestyle='-', linewidth=2, markersize=8)\n",
        "plt.xlabel('Número da Iteração LOSO', fontsize=12)\n",
        "plt.ylabel('UF1', fontsize=12)\n",
        "plt.title('UF1 por Iteração LOSO ', fontsize=14)\n",
        "plt.xticks(subjects)  # Garante todos os sujeitos no eixo\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.savefig('UF1_por_IT.png')  # Salva a figura\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LD-xr4vDei59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VRQhdVfc4kfM"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download(name_instance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9s_ByXndxfm"
      },
      "outputs": [],
      "source": [
        "def print_confusionMatrix(y_true, y_pred):\n",
        "  from sklearn.metrics import confusion_matrix\n",
        "  import seaborn as sns\n",
        "  import matplotlib.pyplot as plt\n",
        "  conf_matrixAdmp = confusion_matrix(y_true, y_pred)\n",
        "  ax = sns.heatmap(conf_matrixAdmp, annot=True, cmap='Blues')\n",
        "\n",
        "  ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
        "  ax.set_xlabel('\\nPredicted Values')\n",
        "  ax.set_ylabel('Actual Values ');\n",
        "\n",
        "  ## Ticket labels - List must be in alphabetical order\n",
        "  ax.xaxis.set_ticklabels(['Positivo','Negativo','Surpresa'])\n",
        "  ax.yaxis.set_ticklabels(['Positivo','Negativo','Surpresa'])\n",
        "\n",
        "  ## Display the visualization of the Confusion Matrix.\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJZ1rzf6x_Ys"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "path = '/content/'+ name_instance\n",
        "with open(path, \"rb\") as arquivo:\n",
        "   e = pickle.load(arquivo)\n",
        "Y_trueAdmp, Y_predAdmp = e['Y_true'], e['Y_pred']\n",
        "acc = accuracy_score(Y_trueAdmp, Y_predAdmp)\n",
        "uar, uf1 = e['meter'].value()\n",
        "print(uar,uar.mean())\n",
        "print(uf1,uf1.mean())\n",
        "print(acc)\n",
        "print_confusionMatrix(Y_trueAdmp, Y_predAdmp)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "yL_6qvDnB7_0"
      ],
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "mount_file_id": "1ulX3EeEhE3UStlj98QN7648ZBZkl5yH-",
      "authorship_tag": "ABX9TyN1OYw6j3SCx9WX2fIoz/lV",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}